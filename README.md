# Udacity Machine Learning Engineer

## Capstone Project Proposal

A proposal for Udacity Machine Learning Engineer Capstone Project.

The proposed project is the Kaggle competition - [Jigsaw unintended bias in toxicity classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview)

Field: Natural Language Processing

## Domain Background

Natural Language Processing is a complex field which is hypothesised to be part of AI-complete set of problems, 
implying that the difficulty of these computational problems is equivalent to that of solving the central artificial 
intelligence problem making computers as intelligent as people. [[cit. Wikipedia]](https://en.wikipedia.org/wiki/AI-complete)

With over 90% of data ever generated being produced in the last 2 years [[ref.ScienceDaily]](https://www.sciencedaily.com/releases/2013/05/130522085217.htm) and with a great proportion being human generated 
unstructured text there is an ever increasing need to advance the field of Natural Language Processing.

Recent UK Government proposal to have measures to regulate social media companies over harmful content, including 
"substantial" fines and the ability to block services that do not stick to the rules is an example of the regulamentory 
need to better manage the content that is being generated by users. [[ref. BBC]](https://www.bbc.co.uk/news/technology-47135058)

Other initiatives like [Riot Games](https://www.riotgames.com/en)'s work aimed to predict and reform toxic player 
behaviour during games[[ref. ArsTechnica]](https://arstechnica.com/gaming/2013/05/using-science-to-reform-toxic-player-behavior-in-league-of-legends/) is another 
example of this effort to understand the content being generated by users and moderate toxic content.

However, as highlighted by the Kaggle competition [Jigsaw unintended bias in toxicity classification](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview), existing models suffer 
from unintended bias where models might predict high likelihood of toxicity for content containing certain words 
(e.g. "gay") even when those comments were not actually toxic (such as "I am a gay woman"), leaving  machine only 
classification models still sub-standard.

Having tools that are able to flag up toxic content without suffering from unintended bias is of paramount importance 
to preserve Internet's fairness and freedom of speech.
